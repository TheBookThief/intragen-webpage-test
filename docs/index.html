<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>InTraGen: Trajectory-controlled Video Generation</title>
    <link rel="icon" href="assets/icon.png" type="image/png">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
</head>

<body>
    <header>
        <img src="logo.png" alt="InTraGen Logo" height="130">
        <h1 style="font-size: 42px;">InTraGen: Trajectory-controlled Video Generation <br> for Object Interactions</h1>
        <section class="authors-section">
            <p style="font-size: 15px;">
                <a href="https://zuhaoliu.com" target="_blank" class="author-link">Zuhao Liu</a><sup>1,3*</sup>, 
                <a href="https://insait.ai/aleksandar-yanev/" target="_blank" class="author-link">Aleksandar Yanev</a><sup>1*</sup>, 
                <a href="https://ahmad-573.github.io" target="_blank" class="author-link">Ahmad Mahmood</a><sup>1,2</sup>, 
                <a href="https://scholar.google.com/citations?user=K2m6cxcAAAAJ&hl=en&oi=sra" target="_blank" class="author-link">Ivan Nikolov</a><sup>4</sup>, 
                <a href="https://sam-motamed.github.io" target="_blank" class="author-link">Saman Motamed</a><sup>1</sup>, 
                <a href="https://www.isee-ai.cn/~zhwshi/" target="_blank" class="author-link">Wei-Shi Zheng</a><sup>3</sup>, 
                <a href="https://xiwang1212.github.io/homepage/" target="_blank" class="author-link">Xi Wang</a><sup>1,2</sup>, 
                <a href="https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en&oi=ao" target="_blank" class="author-link">Luc Van Gool</a><sup>1,2</sup>, 
                <a href="https://scholar.google.com/citations?user=W43pvPkAAAAJ&hl=en&oi=ao" target="_blank" class="author-link">Danda Pani Paudel</a><sup>1</sup>
            </p>
            <p style="font-size: 15px;">
                Affiliations: <sup>1</sup>INSAIT, Bulgaria; <sup>2</sup>ETH Zurich, Switzerland; <sup>3</sup>Sun Yat-sen University, China; <sup>4</sup>Aalborg University, Denmark
            </p>
        </section>
        <ul class="nav nav-pills">
            <li><a target="_blank" href="https://arxiv.org/abs/2411.16804" class="nav-item">
                <img src="assets/images/arxiv.png" height="25px" alt="arXiv"> <u>Arxiv</u></a></li>
            <li><a target="_blank" href="https://arxiv.org/pdf/2411.16804" class="nav-item">
                <img src="assets/images/book_logo_blue.png" height="25px" alt="Paper"> <u>Paper</u></a></li>
            <li><a target="_blank" href="https://github.com/insait-institute/InTraGen" class="nav-item">
                <img src="assets/images/github.png" height="25px" alt="Code"> <u>Code</u></a></li>
        </ul>
    </header>

    <main class="container">
        <section class="video-intro">
            <p>
                <img src="assets/intragen.gif" alt="WHAAA">
            </p>
        </section>

        <section class="content-section summary-section">
            <h2>Abstract</h2>
            <p>
                InTraGen introduces a novel pipeline for generating realistic object interaction scenarios using trajectory control. By leveraging a multi-modal interaction encoding pipeline and object ID injection, it enhances interactions between objects and their environment. Four new datasets and a trajectory quality metric are proposed for evaluation. Results demonstrate improved visual fidelity and quantitative performance.
            </p>
            <img src="assets/images/summary_image.png" alt="Abstract Illustration">
        </section>

        <section class="content-section contributions-section">
            <h2>Key Contributions</h2>
            <ul>
                <li> Introduction of a multi-modal interaction encoding pipeline that integrates sparse pose encoding and object ID maps. </li>
                <li> Development of the Video Interaction (ViN) dataset with four subsets: Pool, Dominoes, Football, and MOVi-Extended. </li>
                <li> Proposal of a new evaluation metric, the Matching Trajectory Evaluation Metric (MTEM), for trajectory quality assessment. </li>
                <li> Extensive experiments showcasing improvements in trajectory adherence and interaction realism over baseline methods. </li>
                <li> Use of a Diffusion Transformer (DiT) for long-term video generation, guided by trajectory conditions. </li>
            </ul>
            <!-- <img src="assets/contributions_image.jpg" alt="Contributions Overview"> -->
        </section>

        <section class="content-section methods-section">
            <h2>Methods</h2>
            <p>
                InTraGen leverages a multi-modal interaction encoding mechanism, which integrates sparse pose encoding and object ID maps to capture dynamic, static, and interactive information. The method employs a Diffusion Transformer (DiT) for long-term video generation, guided by trajectory conditions.
            </p>
            <img src="assets/images/methods_image.png" alt="Methods Diagram">
        </section>

        <section class="content-section dataset-section">
            <h2>Datasets</h2>
            <p>
                The Video Interaction (ViN) dataset is introduced, containing four subsets: Pool, Dominoes, Football, and MOVi-Extended. These datasets feature diverse scenes, high-quality visuals, and rich object interactions. Ground truth trajectories and various evaluation metrics are included to support model training and validation.
            </p>
            <img src="assets/images/dataset_image.png" alt="Datasets Illustration">
        </section>

        <section class="content-section experiments-section">
            <h2>Experiments</h2>
            <p>
                Extensive experiments were conducted to evaluate InTraGen's performance. Metrics such as Matching Trajectory Evaluation Metric (MTEM), SSIM, PSNR, LPIPS, and FID were used to demonstrate improvements over baseline methods.
            </p>
            <img src="assets/images/experiments_image.png" alt="Experiments Chart">
        </section>

        <section class="content-section results-section">
            <h2>Results</h2>
            <p>
                InTraGen achieves superior results in trajectory adherence and interaction realism. Quantitative comparisons and user studies confirm its effectiveness. Qualitative examples highlight the realistic and visually pleasing outputs generated by the model.
            </p>
            <!-- Video Embeds -->
            <div class="video-container">
                <video controls poster="logo.png" width="100%">
                    <source src="assets/Video_Samples/Domino Dataset/sample1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <!-- <p class="video-caption"></p> -->

                <video controls poster="logo.png" width="100%">
                    <source src="assets/Video_Samples/Pool Dataset/sample2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <!-- <p class="video-caption">Video 2: Realistic object interaction scenario.</p> -->
            </div>
            <!-- <img src="assets/images/results_image.png" alt="Results Visualization"> -->
        </section>

        

    </main>

    <footer>
        <p>&copy; 2025 InTraGen Project. All Rights Reserved.</p>
    </footer>
</body>

</html>
